<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yu Zhang</title>
  
  <meta name="author" content="Yu Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yu Zhang</name>
              </p>
              <p>Currently I work as a vice research director with SenseTime Research</a>.
              </p>
              <p>
              At SenseTime I've work on <a href="https://www.sensetime.com/en/product-detail?categoryId=1158">SensePhoto</a>, the state-of-the-art mobile photography solution dilivered to major smartphone OEMs. I earned my PhD at <a href="http://scse.buaa.edu.cn/info/1127/2313.htm">Beihang University</a>, advised by Prof. <a href="http://scse.buaa.edu.cn/info/1121/2547.htm">Qinping Zhao</a> and Prof. Bin Zhou. I also work as a visiting researcher at CVTEAM led by Prof. <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>. I did postdoc from 2019 to 2021, advised by Prof. <a href="https://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a> and <a href="http://www.liuyebin.com/">Yebin Liu</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhangyulb@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data_zy/YuZhang-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data_zy/YuZhang-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Nnw2_fEAAAAJ">Google Scholar</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images_zy/portrait_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images_zy/portrait_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I study computer vision, event-based vision, machine learning and optimization. My research lies much in image and video processing with learning and optimization methods.
              </p>
              <p>
              (<sup>&#8224</sup>interns/students &nbsp *corresponding author)
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

           <tr onmouseout="dbvfi_eccv22_stop()" onmouseover="dbvfi_eccv22_start()">
             <td style="padding:20px;width:25%;vertical-align:center">
               <div class="one">
                 <div class="two" id='dbvfi_eccv22_image'><video width=100% height=100% muted autoplay loop>
                 <source src="images_zy/dbvfi_eccv22_after.mp4" type="video/mp4">
                 Your browser does not support the video tag.
                 </video></div>
                 <img src='images_zy/dbvfi_eccv22_before.png' width="160">
               </div>
               <script type="text/javascript">
                 function dbvfi_eccv22_start() {
                   document.getElementById('dbvfi_eccv22_image').style.opacity = "1";
                 }

                 function dbvfi_eccv22_stop() {
                   document.getElementById('dbvfi_eccv22_image').style.opacity = "0";
                 }
                 dbvfi_eccv22_stop()
               </script>
             </td>
             <td style="padding:20px;width:75%;vertical-align:middle">
                 <papertitle>Deep Bayesian Video Frame Interpolation</papertitle>
               <br>
               Zhiyang Yu<sup>&#8224</sup>,
               <strong>Yu Zhang<sup>*</sup></strong>,
	       Xujie Xiang,
              <a href="https://cn.linkedin.com/in/dongqing-zou-ab734797">Dongqing Zou</a>,
              Xijun Chen,
              <a href="http://www.jimmyren.com/">Jimmy S. Ren</a>
               <br>
                 <em>ECCV</em>, 2022
               <br>
	       paper 
	       /
	       code
               <p></p>
               <p>By encoding the VFI prior into a few unfolded, learned gradient descent steps under the Bayesian regularization framework, our new VFI model achieves state-of-the-art results with only half the parameters of existing models, while showing better generalizability.
             </td>
           </tr>  


            <tr onmouseout="p2p_tpami22_stop()" onmouseover="p2p_tpami22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='p2p_tpami22_image'><img src="images_zy/p2p_tpami22.png" width="160"></div>
                <img src='images_zy/p2p_tpami22.png' width="160">
              </div>
              <script type="text/javascript">
                function p2p_tpami22_start() {
                  document.getElementById('p2p_tpami22_image').style.opacity = "1";
                }

                function p2p_tpami22_stop() {
                  document.getElementById('p2p_tpami22_image').style.opacity = "0";
                }
                p2p_tpami22_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>From Pose to Part: Weakly-Supervised Pose Evolution for Human Part Segmentation</papertitle>
              <br>
              Yifan Zhao,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              <strong>Yu, Zhang</strong>,
              <a href="https://www.pkuml.org/staff/yhtian.html">Yonghong Tian</a>
              <br>
              <em>IEEE TPAMI</em>, 2022 &nbsp 

              <br>
              <a href="https://pubmed.ncbi.nlm.nih.gov/35544512/">paper</a>
              /
              code
              <p>Human part segmentation can be conducted without dense pixel-level annotations by evolving a coarse part class map with image boundary cues, constrained by pose and object-level annotations.
            </td>
          </tr> 

           <tr onmouseout="smt_iccv21_stop()" onmouseover="smt_iccv21_start()">
             <td style="padding:20px;width:25%;vertical-align:middle">
               <div class="one">
                 <div class="two" id='smt_iccv21_image'><video width=100% height=100% muted autoplay loop>
                 <source src="images_zy/smt_iccv21_after.mp4" type="video/mp4">
                 Your browser does not support the video tag.
                 </video></div>
                 <img src='images_zy/smt_iccv21_before.png' width="160">
               </div>
               <script type="text/javascript">
                 function smt_iccv21_start() {
                   document.getElementById('smt_iccv21_image').style.opacity = "1";
                 }

                 function smt_iccv21_stop() {
                   document.getElementById('smt_iccv21_image').style.opacity = "0";
                 }
                 smt_iccv21_stop()
               </script>
             </td>
             <td style="padding:20px;width:75%;vertical-align:middle">
                 <papertitle>Training Weakly Supervised Video Frame Interpolation with Events</papertitle>
               <br>
               Zhiyang Yu<sup>&#8224</sup>,
               <strong>Yu Zhang<sup>*</sup></strong>,
               Deyuan Liu,
              <a href="https://cn.linkedin.com/in/dongqing-zou-ab734797">Dongqing Zou</a>,
              Xijun Chen,
              <a href="http://www.liuyebin.com/">Yebin Liu</a>.
              <a href="http://www.jimmyren.com/">Jimmy S. Ren</a>
               <br>
                 <em>ICCV</em>, 2021
               <br>
               <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_Training_Weakly_Supervised_Video_Frame_Interpolation_With_Events_ICCV_2021_paper.pdf">paper</a>/
               <a href="https://github.com/YU-Zhiyang/WEVI">code</a>
               <p></p>
               <p>Using an event camera allows you to train video interpolation models without the need of high frame-rate videos.</p>
             </td>
           </tr>  

            <tr onmouseout="letgan_mm21_stop()" onmouseover="letgan_mm21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='letgan_mm21_image'><img src="images_zy/LETGAN_mm21_after.png" width="160"></div>
                <img src='images_zy/LETGAN_mm21_before.png' width="160">
              </div>
              <script type="text/javascript">
                function letgan_mm21_start() {
                  document.getElementById('letgan_mm21_image').style.opacity = "1";
                }

                function letgan_mm21_stop() {
                  document.getElementById('letgan_mm21_image').style.opacity = "0";
                }
                letgan_mm21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>How to Learn a Domain Adaptive Event Simulator?</papertitle>
              <br>
              Daxin Gu<sup>&#8224</sup>,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              <strong>Yu, Zhang*</strong>,
              <a href="https://www.pkuml.org/staff/yhtian.html">Yonghong Tian</a>
              <br>
              <em>ACM MM</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>

              <br>
              <a href="https://dlnext.acm.org/doi/abs/10.1145/3474085.3475229">paper</a>
              /
              <a href="https://github.com/iCVTEAM/LETGAN">code</a>
              <p>A fully trainable white-box event camera simulator with divide-and-conquer domain adaptation that automatically calibrate its parameters towards target domain.</p>
            </td>
          </tr> 

            <tr onmouseout="iccm_cvpr21_stop()" onmouseover="iccm_cvpr21_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='iccm_cvpr21_image'><img src="images_zy/iccm_cvpr21_after.png" width="160"></div>
                <img src='images_zy/iccm_cvpr21_before.png' width="160">
              </div>
              <script type="text/javascript">
                function iccm_cvpr21_start() {
                  document.getElementById('iccm_cvpr21_image').style.opacity = "1";
                }

                function iccm_cvpr21_stop() {
                  document.getElementById('iccm_cvpr21_image').style.opacity = "0";
                }
                iccm_cvpr21_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Informative and Consistent Correspondence Mining for Cross-Domain Weakly Supervised Object Detection</papertitle>
              <br>
              Luwei Hou<sup>&#8224</sup>,
              <strong>Yu, Zhang*</strong>,
              Kui Fu,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>

              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Informative_and_Consistent_Correspondence_Mining_for_Cross-Domain_Weakly_Supervised_Object_CVPR_2021_paper.html">paper</a>
              /
              <a href="data_zy/iccm_cvpr21_supp.pdf">supp.</a>
              <p>Cross-domain pixel-level correspondences can be learned in weakly supervised manner for object detector adaptation.</p>
            </td>
          </tr> 

          <tr onmouseout="lsde_eccv20_stop()" onmouseover="lsde_eccv20_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='lsde_eccv20_image'><img src="images_zy/lsde_eccv20_after.png" width="160"></div>
                <img src='images_zy/lsde_eccv20_before.png' width="160">
              </div>
              <script type="text/javascript">
                function lsde_eccv20_start() {
                  document.getElementById('lsde_eccv20_image').style.opacity = "1";
                }

                function lsde_eccv20_stop() {
                  document.getElementById('lsde_eccv20_image').style.opacity = "0";
                }
                lsde_eccv20_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning to See in the Dark with Events</papertitle>
              <br>
              Song Zhang<sup>&#8224</sup>,
              <strong>Yu Zhang*</strong>,
              Zhe Jiang<sup>&#8224</sup>,
              <a href="https://cn.linkedin.com/in/dongqing-zou-ab734797">Dongqing Zou</a>,
              <a href="http://www.jimmyren.com/">Jimmy S. Ren</a>,
              <a href="https://scholar.google.com/citations?user=tG4RnyYAAAAJ&hl=en">Bin Zhou</a>
              <br>
              <em>ECCV</em>, 2020
              <br>
              <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630647.pdf">paper</a> /
              <a href="https://github.com/zhangsongchn/DVS-Dark/tree/master">code</a>
              <p>Unpaired image translation from low light to day light can be achieved by the HDR of event streams captured by an event camera. </p>
            </td>
          </tr>

          <tr onmouseout="mmka_tip20_stop()" onmouseover="mmka_tip20_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images_zy/mmka_tip20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Model-guided Multi-path Knowledge Aggregation for Aerial Saliency Prediction</papertitle>
              </a>
              <br>
              Kui Fu,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              <strong>Yu Zhang</strong>,
              Hongze Shen,
              <a href="https://www.pkuml.org/staff/yhtian.html">Yonghong Tian</a>
              <br>
              <em>TIP</em>, 2020
              <br>
              <a href="http://cvteam.net/papers/2020-TIP-Fu-Model-guided%20Multi-path%20Knowledge%20Aggregation%20for%20Aerial%20Saliency%20Prediction.pdf">paper</a> /
              <a href="http://gofile.me/4Hwyd/nazC54Ib0">dataset(ID:3yd8,password:cvteam)</a>
              <p></p>
              <p>A dataset for aerial saliency detection and how to adapt existing saliency models to this task.</p>
            </td>
          </tr>


          <tr onmouseout="lrfr_tip20_stop()" onmouseover="lrfr_tip20_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images_zy/lrfr_tip20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Efficient Low-resolution Face Recognition via Bridge Ditillation</papertitle>
              <br>
              <a href="https://imsg.ac.cn/">Shiming Ge</a>,
              Shengwei Zhao,
              Chenyu Li,
              <strong>Yu Zhang</strong>,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>
              <br>
              <em>TIP</em>, 2020 
              <br>
              <a href="http://cvteam.net/papers/2020-TIP-Efficient%20Low-Resolution%20Face%20Recognition%20via%20Bridge%20Distillation.pdf">paper</a>
              <p></p>
              <p>Simply learning feature super-resolution and knowledge distillation in multi-task way produces an accurate face detector capable of processing 763 faces/s on mobile phone.</p>
            </td>
          </tr>

          <tr onmouseout="lemd_cvpr20_stop()" onmouseover="lemd_cvpr20_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lemd_cvpr20_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_zy/lemd_cvpr20_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_zy/lemd_cvpr20_before.png' width="160">
              </div>
              <script type="text/javascript">
                function lemd_cvpr20_start() {
                  document.getElementById('lemd_cvpr20_image').style.opacity = "1";
                }
                function lemd_cvpr20_stop() {
                  document.getElementById('lemd_cvpr20_image').style.opacity = "0";
                }
                lemd_cvpr20_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Event-based Motion Deblurring</papertitle>
              <br>
              Zhe Jiang<sup>&#8224</sup>*,
              <strong>Yu Zhang*</strong>,
              <a href="https://cn.linkedin.com/in/dongqing-zou-ab734797">Dongqing Zou</a>,
              <a href="http://www.jimmyren.com/">Jimmy S. Ren</a>,
              Jiancheng Lv,
              <a href="http://www.liuyebin.com/">Yebin Liu</a>
              <br>
              <em>CVPR</em>, 2020  
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_Learning_Event-Based_Motion_Deblurring_CVPR_2020_paper.pdf">paper</a> /
              code
              <p></p>
              <p>An end-to-end learning pipeline that restores a motion blurred image to a video sequence using event camera.
              </p>
            </td>
          </tr> 

          <tr onmouseout="omps_tpami20_stop()" onmouseover="omps_tpami20_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images_zy/omps_tpami20.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Ordinal Multi-task Part Segmentation with Recurrent Prior Generation</papertitle>
              <br>
              Yifan Zhao,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              <strong>Yu Zhang</strong>,
              <a href="https://scholar.google.com/citations?user=VMO6UOgAAAAJ&hl=en">Yafei Song</a>,
              <a href="https://www.pkuml.org/staff/yhtian.html">Yonghong Tian</a>
              <br>
              <em>TPAMI</em>, 2020
              <br>
              <a href="http://cvteam.net/papers/2020-TPAMI-Ordinal%20Multi-task%20Part%20Segmentation%20with%20Recurrent%20Prior%20Generation.pdf">paper</a>
              <p></p>
              <p>Useful context information can be mined by optimizing the processing order of parts in semantic part parsing.</p>
            </td>
          </tr> 

          <tr onmouseout="mcpp_iccv19_stop()" onmouseover="mcpp_iccv19_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='mcpp_iccv19_image'><img src="images_zy/mcpp_iccv19_after.png" width="160"></div>
                <img src='images_zy/mcpp_iccv19_before.png' width="160">
              </div>
              <script type="text/javascript">
                function mcpp_iccv19_start() {
                  document.getElementById('mcpp_iccv19_image').style.opacity = "1";
                }
                function mcpp_iccv19_stop() {
                  document.getElementById('mcpp_iccv19_image').style.opacity = "0";
                }
                mcpp_iccv19_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://cvteam.net/projects/2019/multiclass-part.html">
                  <papertitle>Multi-class Part Parsing with Joint Boundary-Semantic Awareness</papertitle>
              </a>
              <br>
              Yifan Zhao,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              <strong>Yu Zhang</strong>,
              <a href="https://www.pkuml.org/staff/yhtian.html">Yonghong Tian</a>
              <br>
              <em>ICCV</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://cvteam.net/projects/2019/multiclass-part.html">project page</a> /
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhao_Multi-Class_Part_Parsing_With_Joint_Boundary-Semantic_Awareness_ICCV_2019_paper.pdf">paper</a> 
              <p></p>
              <p>Semantic part parsing benefits from jointly processing multiple classes by attending to part boundaries and class discrimination.
              </p>
            </td>
          </tr> 


          <tr onmouseout="bsod_iccv19_stop()" onmouseover="bsod_iccv19_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='bsod_iccv19_image'><img src="images_zy/bsod_iccv19_after.png" width="160"></div>
                <img src='images_zy/bsod_iccv19_before.png' width="160">
              </div>
              <script type="text/javascript">
                function bsod_iccv19_start() {
                  document.getElementById('bsod_iccv19_image').style.opacity = "1";
                }

                function bsod_iccv19_stop() {
                  document.getElementById('bsod_iccv19_image').style.opacity = "0";
                }
                nerd_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://cvteam.net/projects/ICCV19-SOD/BANet.html">
                    <papertitle>Selectivity or Invariance: Boundary-aware Salient Object Detection</papertitle>
              </a>
              <br>
              Jinming Su,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              <strong>Yu Zhang</strong>,
              <a href="https://changqunxia.github.io/">Changqun Xia</a>
              <a href="https://www.pkuml.org/staff/yhtian.html">Yonghong Tian</a>
              <br>
              <em>ICCV</em>, 2019
              <br>
              <a href="http://cvteam.net/projects/ICCV19-SOD/BANet.html">project page</a> /
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Su_Selectivity_or_Invariance_Boundary-Aware_Salient_Object_Detection_ICCV_2019_paper.pdf">paper</a>
              <p></p>
              <p>
              Modeling the transitions across object boundaries helps salient object segmentation.
              </p>
            </td>
          </tr>

          <tr onmouseout="crsqa_mm19_stop()" onmouseover="crsqa_mm19_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='crsqa_mm19_image'><img src="images_zy/crsqa_mm19_after.png" width="160"></div>
                <img src='images_zy/crsqa_mm19_before.png' width="160">
              </div>
              <script type="text/javascript">
                function crsqa_mm19_start() {
                  document.getElementById('crsqa_mm19_image').style.opacity = "1";
                }

                function crsqa_mm19_stop() {
                  document.getElementById('crsqa_mm19_image').style.opacity = "0";
                }
                nerd_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://cvteam.net/projects/MM19-CROSS/MM2019.html"
                    <papertitle>Cross-Reference Stitching Quality Assessment for 360<sup>&#113813</sup> Omnidirectional Images</papertitle>
              </a>
              <br>
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Kaiwen Yu,
              Yifan Zhao,
              <strong>Yu Zhang</strong>,
              <a href="https://scholar.google.com.sg/citations?user=PBqivgkAAAAJ&hl=en">Long Xu</a>
              <br>
              <em>ACM MM</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://cvteam.net/projects/MM19-CROSS/MM2019.html">project page</a> /
              <a href="https://arxiv.org/abs/1904.04960">paper</a>
              <p></p>
              <p>
              A new dataset for omnidirectional image stitching and novel metrics for assessing the quality of related algorithms.
              </p>
            </td>
          </tr>


          <tr onmouseout="macm_cvpr19_stop()" onmouseover="macm_cvpr19_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='macm_cvpr19_image'><img src="images_zy/macm_cvpr19_after.png" width="160"></div>
                <img src='images_zy/macm_cvpr19_before.png' width="160">
              </div>
              <script type="text/javascript">
                function macm_cvpr19_start() {
                  document.getElementById('macm_cvpr19_image').style.opacity = "1";
                }
                function macm_cvpr19_stop() {
                  document.getElementById('macm_cvpr19_image').style.opacity = "0";
                }
                macm_cvpr19_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Structure-Preserving_Stereoscopic_View_Synthesis_With_Multi-Scale_Adversarial_Correlation_Matching_CVPR_2019_paper.pdf">Structure-Preserving Stereoscopic View Synthesis with Multiscale Adversarial Correlation Matching</a></papertitle>
              <br>
              <strong>Yu Zhang</strong>,
              <a href="https://cn.linkedin.com/in/dongqing-zou-ab734797">Dongqing Zou</a>,
              <a href="http://www.jimmyren.com/">Jimmy S. Ren</a>,
              Zhe Jiang,
              Xiaohao Chen
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Structure-Preserving_Stereoscopic_View_Synthesis_With_Multi-Scale_Adversarial_Correlation_Matching_CVPR_2019_paper.pdf">paper</a> /
              <a href="data_zy/macm_cvpr19_supp">supp.</a> 
              <p></p>
              <p>Multiscale adversarial training on feature correlations defines unsupervised structural preservation loss for novel view synthesize.
              </p>
            </td>
          </tr> 

          <tr onmouseout="dmsr_tvc18_stop()" onmouseover="dmsr_tvc18_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dmsr_tvc18_image'>
                  <img src='images_zy/dmsr_tvc18_after.png' width="160"></div>
                <img src='images_zy/dmsr_tvc18_before.png' width="160">
              </div>
              <script type="text/javascript">
                function dmsr_tvc18_start() {
                  document.getElementById('dmsr_tvc18_image').style.opacity = "1";
                }

                function dmsr_tvc18_stop() {
                  document.getElementById('dmsr_tvc18_image').style.opacity = "0";
                }
                dmsr_tvc18_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Real-time 3D Scene Reconstruction with Dynamically Moving Object using a Single Depth Camera</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=2Kem6bIAAAAJ&hl=zh-CN">Feixiang Lu</a>,
              <a href="https://scholar.google.com/citations?user=tG4RnyYAAAAJ&hl=en">Bin Zhou</a>,
              <strong>Yu Zhang</strong>,
              <a href="http://scse.buaa.edu.cn/info/1121/2547.htm">Qinping Zhao</a>
              <br>
              <em>TVC</em>, 2018 &nbsp <font color="red"><strong>(Best Paper Award of CGI 2018)</strong></font>
 
              <br>
              <a href="https://link.springer.com/article/10.1007/s00371-018-1540-8">paper</a> 
              <p></p>
              <p>
              By improving reference frame selection and 6D pose prediction, we reconstruct dynamic objects in real-time while handling large motion.
              </p>
            </td>
          </tr> 


          <tr onmouseout="sps_tip18_stop()" onmouseover="sps_tip18_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sps_tip18_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images_zy/sps_tip18_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_zy/sps_tip18_before.png' width="160">
              </div>
              <script type="text/javascript">
                function sps_tip18_start() {
                  document.getElementById('sps_tip18_image').style.opacity = "1";
                }

                function sps_tip18_stop() {
                  document.getElementById('sps_tip18_image').style.opacity = "0";
                }
                sps_tip18_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Exploring Weakly Labeled Images for Video Object Segmentation with Submodular Proposal Selection</papertitle>
              <br>
              <strong>Yu Zhang</strong>,
              Xiaowu Chen,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Wei Teng,
              Haokun Song
              <br>
              <em>TIP</em>, 2018
              <br>
              <a href="http://cvteam.net/papers/2018_TIP_Zhang-Exploring%20Weakly%20Labeled%20Images%20for%20Video%20Object%20Segmentation%20with%20Submodular%20Proposal%20Selection.pdf">paper</a> /
              <a href="http://cvteam.net/projects/TIP18-Exploring/TIP2018_results.zip">results</a>
              <p></p>
              <p>Modeling object part relations with simple priors enables accurate object localization in videos with weak supervision.
            </td>
          </tr> 

          <tr onmouseout="lll_cvpr17_stop()" onmouseover="lll_cvpr17_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lll_cvpr17_image'>
                  <img src='images_zy/lll_cvpr17_after.png' width="160"></div>
                <img src='images_zy/lll_cvpr17_before.png' width="160">
              </div>
              <script type="text/javascript">
                function lll_cvpr17_start() {
                  document.getElementById('lll_cvpr17_image').style.opacity = "1";
                }

                function lll_cvpr17_stop() {
                  document.getElementById('lll_cvpr17_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://cvteam.net/projects/CVPR17-ELE/ELE.html">
                <papertitle>What is and What is not a Salient Object? Learning Salient Object Detector by Ensembling Linear Exemplar Regressors</papertitle>
              </a>
              <br>
              <a href="https://changqunxia.github.io/">Changqun Xia</a>,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Xiaowu Chen,
              Anlin Zheng,
              <strong>Yu Zhang</strong>
              <br>
              <em>CVPR</em>, 2017 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
              <a href="http://cvteam.net/projects/CVPR17-ELE/ELE.html">project</a> /
              <a href="http://cvteam.net/papers/2017_CVPR_Xia_What%20is%20and%20What%20is%20not%20a%20salient%20object%20Learning%20Salient%20Object%20Detector%20by%20Ensembling%20Linear%20Exemplar%20Regressors.pdf">paper</a> /
              <a href="http://cvteam.net/projects/CVPR17-ELE/ELE-Result.zip">results</a> /
              <a href="http://cvteam.net/projects/CVPR17-ELE/XPIE.tar.gz">data</a>
              <p></p>
              <p>Exemplar detectors are explored to learn instance-specific saliency patterns and a large saliency detection dataset is proposed.</p>
            </td>
          </tr> 

    
          <tr onmouseout="sod_tpami17_stop()" onmouseover="sod_tpami17_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sod_tpami17_image'>
                  <img src='images_zy/sod_tpami17_after.png' width="160"></div>
                <img src='images_zy/sod_tpami17_before.png' width="160">
              </div>
              <script type="text/javascript">
                function sod_tpami17_start() {
                  document.getElementById('sod_tpami17_image').style.opacity = "1";
                }

                function sod_tpami17_stop() {
                  document.getElementById('sod_tpami17_image').style.opacity = "0";
                }
                sod_tpami17_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Semantic Object Segmentation in Tagged Videos via Detection</papertitle>
              <br>
              <strong>Yu Zhang</strong>,
              Xiaowu Chen,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Chen Wang,
              <a href="https://changqunxia.github.io/">Changqun Xia</a>,
              Jun Li
              <br>
              <em>TPAMI</em>, 2017
              <br>
              <a href="http://cvteam.net/papers/2018_TPAMI_Semantic%20Object%20Segmentation%20in%20Tagged%20Videos%20via%20Detection.pdf">paper</a>
              <br>
              <p></p>
              <p>
              Extended version of CVPR 2015 with improved network flow solver and object shape prior.
              </p>
            </td>
          </tr>  
    
          <tr onmouseout="dof_tmm16_stop()" onmouseover="dof_tmm16_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dof_tmm16_image'>
                  <img src='images_zy/dof_tmm16_after.png' width="160"></div>
                <img src='images_zy/dof_tmm16_before.png' width="160">
              </div>
              <script type="text/javascript">
                function dof_tmm16_start() {
                  document.getElementById('dof_tmm16_image').style.opacity = "1";
                }

                function dof_tmm16_stop() {
                  document.getElementById('dof_tmm16_image').style.opacity = "0";
                }
                dof_tmm16_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>6-DOF Image Localization from Massive Geo-tagged Reference Images</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=VMO6UOgAAAAJ&hl=en">Yafei Song</a>,
              Xiaowu Chen,
              Xiaogang Wang,
              <strong>Yu Zhang</strong>,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>
              <br>
              <em>TMM</em>, 2016 &nbsp <font color="red"><strong>(Best Paper Award of IEEE BigMM 2015)</strong></font>
              <br>
              <a href="http://cvteam.net/papers/2016_TMM_6-DOF%20Image%20Localization%20from%20Massive%20Geo-tagged%20Reference%20Images.pdf">paper</a>
              <p></p>
              <p>
              Searching for the posed images with appearance similar to the input image can uniquely determine its pose with fast inference.
            </td>
          </tr> 

          <tr onmouseout="lst_bmvc16_stop()" onmouseover="lst_bmvc16_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lst_bmvc16_image'>
                  <img src='images_zy/lst_bmvc16_after.png' width="160"></div>
                <img src='images_zy/lst_bmvc16_before.png' width="160">
              </div>
              <script type="text/javascript">
                function lst_bmvc16_start() {
                  document.getElementById('lst_bmvc16_image').style.opacity = "1";
                }

                function lst_bmvc16_stop() {
                  document.getElementById('lst_bmvc16_image').style.opacity = "0";
                }
                lst_bmvc16_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Local Shape Transfer for Image Co-segmentation</papertitle>
              <br>
              Wei Teng*,
              <strong>Yu Zhang*</strong>,
              Xiaowu Chen,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Zhiqiang He
              <br>
              <em>BMVC</em>, 2016 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://www.bmva.org/bmvc/2016/papers/paper003/paper003.pdf">paper</a> / 
              <a href="http://www.bmva.org/bmvc/2016/papers/paper003/abstract003.pdf">extended abstract</a>
              <p></p>
              <p>Shapes of local image patches lie in low-dimensional manifold, which is a consistency regularizer for image co-segmentation.</p>
            </td>
          </tr>  

          <tr onmouseout="mwc_icme15_stop()" onmouseover="mwc_icme15_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mwc_icme15_image'>
                  <img src='images_zy/mwc_icme15_after.png' width="160"></div>
                <img src='images_zy/mwc_icme15_before.png' width="160">
              </div>
              <script type="text/javascript">
                function mwc_icme15_start() {
                  document.getElementById('mwc_icme15_image').style.opacity = "1";
                }

                function mwc_icme15_stop() {
                  document.getElementById('mwc_icme15_image').style.opacity = "0";
                }
                mwc_icme15_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Cuboids detection in RGB-D images via maximum weighted clique</papertitle>
              <br>
              Han Zhang,
              Xiaowu Chen,
              <strong>Yu Zhang</strong>,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Qing Li,
              Xiaogang Wang
              <br>
              <em>ICME</em>, 2015
              <br>
              <a href="https://ieeexplore.ieee.org/document/7177405">paper</a> 
              <p></p>
              <p>By incorporating global layout consistency modelled with maximum weighted clique, previous detection rate of cuboid proposals in RGBD images is doubled.</p>
            </td>
          </tr>  

          <tr onmouseout="sod_cvpr15_stop()" onmouseover="sod_cvpr15_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sod_cvpr15_image'><video width=100% height=100% muted autoplay loop>
                <source src="images_zy/sod_cvpr15_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_zy/sod_cvpr15_before.png' width="160">
              </div>
              <script type="text/javascript">
                function sod_cvpr15_start() {
                  document.getElementById('sod_cvpr15_image').style.opacity = "1";
                }

                function sod_cvpr15_stop() {
                  document.getElementById('sod_cvpr15_image').style.opacity = "0";
                }
                sod_cvpr15_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Semantic Object Segmentation via
                Detection in Weakly Labeled Video</papertitle>
              <br>
              <strong>Yu Zhang</strong>,
              Xiaowu Chen,
              <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a>,
              Chen Wang,
              <a href="https://changqunxia.github.io/">Changqun Xia</a>
              <br>
        <em>CVPR</em>, 2015 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Zhang_Semantic_Object_Segmentation_2015_CVPR_paper.pdf">paper</a>
              <p></p>
              <p>Weak object detectors can generate strong video object segmentation results via joint inference with a quadratic network flow model.</p>
            </td>
          </tr>  

          <tr onmouseout="gp_tip14_stop()" onmouseover="gp_tip14_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='gp_tip14_image'><video width=100% height=100% muted autoplay loop>
                <source src="images_zy/gp_tip14_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images_zy/gp_tip14_before.png' width="160">
              </div>
              <script type="text/javascript">
                function gp_tip14_start() {
                  document.getElementById('gp_tip14_image').style.opacity = "1";
                }

                function gp_tip14_stop() {
                  document.getElementById('gp_tip14_image').style.opacity = "0";
                }
                gp_tip14_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Geodesic Propagation for Semantic Labeling</papertitle>
              <br>
              Qing Li,
              Xiaowu Chen,
              <a href="https://scholar.google.com/citations?user=VMO6UOgAAAAJ&hl=en">Yafei Song</a>,
              <strong>Yu Zhang</strong>
              <br>
        <em>TIP</em>, 2014
              <br>
              <a href="https://ieeexplore.ieee.org/document/6898820">paper</a>
              <p></p>
              <p>We present a fast approach for semantic segmentation by propagating labels along geodesic paths in feature space.</p>
            </td>
          </tr>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Former Interns</heading>
            <p>
	    <strong>Yu Shi</strong>, Undergraduate student from Peking University, internship 2021-2022. Now a graduate student at UCLA.
	    </p>
	    <p>
            <strong>Zhe Jiang</strong>, Master student from Sichuan University, intership 2018-2020. <strong>CVPR 2020</strong> and <strong>ECCV 2020</strong>. Now a PhD student at The Hong Kong Polytechnic University.
            </p>
            <p>
            <strong>Song Zhang</strong>, Master student from Beihang University, intership 2018-2020. <strong>ECCV 2020</strong>. Now a researcher at SenseTime.
            </p>
            <p>
            <strong>Luwei Hou</strong>, Master student from Beihang University, intership 2020-2021. <strong>CVPR 2021</strong>. Now a researcher at SenseTime.
            </td>
          </tr>
        </tbody></table>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Much thanks to <a href="https://jonbarron.info/">Jon Barron</a> for sharing this template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
